{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Использование глубокого обучения в NLP\n",
    "\n",
    "Смотрите в этой серии:\n",
    " * Простые способы работать с текстом, bag of words\n",
    " * Word embedding и... нет, это не word2vec\n",
    " * Как сделать лучше? Текстовые свёрточные сети\n",
    " * Совмещение нескольких различных источников данных\n",
    " * Решение +- реальной задачи нейронками \n",
    " \n",
    "За помощь в организации свёрточной части спасибо Ирине Гольцман"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLTK\n",
    "\n",
    "Для работы этого семинара вам потреюуется nltk v3.2\n",
    "\n",
    "__Важно, что именно v3.2, чтобы правильно работал токенизатор__\n",
    "\n",
    "Устаовить/обновиться до неё можно командой\n",
    "* `sudo pip install --upgrade nltk==3.2`\n",
    "* Если у вас старый pip, предварительно нужно сделать `sudo pip install --upgrade pip`\n",
    "\n",
    "Если у вас нет доступа к этой версии - просто убедитесь, что токены в token_counts включают русские слова."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Для людей со слабым ПК\n",
    " * Этот семинар можно выполнить, имея относительно скромную машину (<= 4Gb RAM) \n",
    " * Для этого существует специальный флаг \"low_RAM_mode\" - если он True, семинар работает в режиме экономии вашей памяти\n",
    " * Если у вас 8GB и больше - проблем с памятью возникнуть не должно\n",
    " * Если включить режим very_low_ram, расход мамяти будет ещё меньше, но вам может быть более трудно научить нейронку."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "low_RAM_mode = True\n",
    "very_low_RAM = False  #если у вас меньше 3GB оперативки, включите оба флага"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Познакомимся с данными\n",
    "\n",
    "Бывший kaggle-конкурс про выявление нежелательного контента.\n",
    "\n",
    "Описание конкурса есть тут - https://www.kaggle.com/c/avito-prohibited-content\n",
    "\n",
    "\n",
    "### Скачать\n",
    "Если много RAM,\n",
    " * Из данных конкурса (вкладка Data) нужно скачать avito_train.tsv и распаковать в папку с тетрадкой\n",
    "Если мало RAM,\n",
    " * Cкачайте прореженную выборку отсюда \n",
    "     * Пожатая https://yadi.sk/d/l0p4lameqw3W8\n",
    "     * Непожатая https://yadi.sk/d/I1v7mZ6Sqw2WK\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Много разных признаков:\n",
    "* 2 вида текста - заголовок и описание\n",
    "* Много специальных фичей - цена, количество телефонов/ссылок/e-mail адресов\n",
    "* Категория и субкатегория - как ни странно, категориальные фичи\n",
    "* Аттрибуты - много категориальных признаков\n",
    "\n",
    "Нужно предсказать всего 1 бинарный признак - есть ли в рекламе нежелательный контент.\n",
    "* Под нежелательным контентом понимается криминал, прон, афера, треска и прочие любимые нами темы.\n",
    "* Да, если присмотреться к заблокированным объявлениям, можно потерять аппетит и сон на пару дней.\n",
    "* Однако профессия аналитика данных обязывает вас смотреть на данные.\n",
    " * А кто сказал, что будет легко? Data Science - опасная профессия.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if not low_RAM_mode:\n",
    "    # Если у вас много оперативки\n",
    "    df = pd.read_csv(\"avito_train.tsv\",sep='\\t')\n",
    "else:\n",
    "    #Если у вас меньше 4gb оперативки\n",
    "    df = pd.read_csv(\"avito_train_1kk.tsv\",sep='\\t')\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1204949, 13) 0.228222107326\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>itemid</th>\n",
       "      <th>category</th>\n",
       "      <th>subcategory</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>attrs</th>\n",
       "      <th>price</th>\n",
       "      <th>is_proved</th>\n",
       "      <th>is_blocked</th>\n",
       "      <th>phones_cnt</th>\n",
       "      <th>emails_cnt</th>\n",
       "      <th>urls_cnt</th>\n",
       "      <th>close_hours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000010</td>\n",
       "      <td>Транспорт</td>\n",
       "      <td>Автомобили с пробегом</td>\n",
       "      <td>Toyota Sera, 1991</td>\n",
       "      <td>Новая оригинальная линзованая оптика на ксенон...</td>\n",
       "      <td>{\"Год выпуска\":\"1991\", \"Тип кузова\":\"Купе\", \"П...</td>\n",
       "      <td>150000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000094</td>\n",
       "      <td>Личные вещи</td>\n",
       "      <td>Одежда, обувь, аксессуары</td>\n",
       "      <td>Костюм Steilmann</td>\n",
       "      <td>Юбка и топ из панбархата. Под топ  трикотажная...</td>\n",
       "      <td>{\"Вид одежды\":\"Женская одежда\", \"Предмет одежд...</td>\n",
       "      <td>1500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10000299</td>\n",
       "      <td>Личные вещи</td>\n",
       "      <td>Детская одежда и обувь</td>\n",
       "      <td>Костюм Didriksons Boardman, размер 100, краги,...</td>\n",
       "      <td>Костюм Didriksons Boardman, в отличном состоян...</td>\n",
       "      <td>{\"Вид одежды\":\"Для мальчиков\", \"Предмет одежды...</td>\n",
       "      <td>3000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000309</td>\n",
       "      <td>Недвижимость</td>\n",
       "      <td>Квартиры</td>\n",
       "      <td>1-к квартира, 44 м², 9/20 эт.</td>\n",
       "      <td>В кирпичном пан.-м доме, продается одноком.-ая...</td>\n",
       "      <td>{\"Тип объявления\":\"Продам\", \"Количество комнат...</td>\n",
       "      <td>2642020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10000317</td>\n",
       "      <td>Услуги</td>\n",
       "      <td>Предложения услуг</td>\n",
       "      <td>Поездки на таможню, печать в паспорте</td>\n",
       "      <td>Поездки на таможню гражданам СНГ для пересечен...</td>\n",
       "      <td>{\"Вид услуги\":\"Деловые услуги\", \"Тип услуги\":\"...</td>\n",
       "      <td>1500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     itemid      category                subcategory  \\\n",
       "0  10000010     Транспорт      Автомобили с пробегом   \n",
       "1  10000094   Личные вещи  Одежда, обувь, аксессуары   \n",
       "2  10000299   Личные вещи     Детская одежда и обувь   \n",
       "3  10000309  Недвижимость                   Квартиры   \n",
       "4  10000317        Услуги          Предложения услуг   \n",
       "\n",
       "                                               title  \\\n",
       "0                                  Toyota Sera, 1991   \n",
       "1                                   Костюм Steilmann   \n",
       "2  Костюм Didriksons Boardman, размер 100, краги,...   \n",
       "3                      1-к квартира, 44 м², 9/20 эт.   \n",
       "4              Поездки на таможню, печать в паспорте   \n",
       "\n",
       "                                         description  \\\n",
       "0  Новая оригинальная линзованая оптика на ксенон...   \n",
       "1  Юбка и топ из панбархата. Под топ  трикотажная...   \n",
       "2  Костюм Didriksons Boardman, в отличном состоян...   \n",
       "3  В кирпичном пан.-м доме, продается одноком.-ая...   \n",
       "4  Поездки на таможню гражданам СНГ для пересечен...   \n",
       "\n",
       "                                               attrs    price  is_proved  \\\n",
       "0  {\"Год выпуска\":\"1991\", \"Тип кузова\":\"Купе\", \"П...   150000        NaN   \n",
       "1  {\"Вид одежды\":\"Женская одежда\", \"Предмет одежд...     1500        NaN   \n",
       "2  {\"Вид одежды\":\"Для мальчиков\", \"Предмет одежды...     3000        NaN   \n",
       "3  {\"Тип объявления\":\"Продам\", \"Количество комнат...  2642020        NaN   \n",
       "4  {\"Вид услуги\":\"Деловые услуги\", \"Тип услуги\":\"...     1500        0.0   \n",
       "\n",
       "   is_blocked  phones_cnt  emails_cnt  urls_cnt  close_hours  \n",
       "0           0           0           0         0         0.03  \n",
       "1           0           0           0         0         0.41  \n",
       "2           0           0           0         0         5.49  \n",
       "3           0           1           0         0        22.47  \n",
       "4           1           0           0         0         1.43  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print df.shape, df.is_blocked.mean()\n",
    "df[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![caption](https://kaggle2.blob.core.windows.net/competitions/kaggle/3929/media/Ad.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Доля заблокированных объявлений 0.228222107326\n",
      "Всего объявлений: 1204949\n"
     ]
    }
   ],
   "source": [
    "print \"Доля заблокированных объявлений\",df.is_blocked.mean()\n",
    "print \"Всего объявлений:\",len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Сбалансируем выборку\n",
    "* Выборка смещена в сторону незаблокированных объявлений\n",
    " * 4 миллиона объявлений и только 250 тысяч заблокированы.\n",
    " * Давайте просто выберем случайные 250 тысяч незаблокированных объявлений и сократим выборку до полумилиона.\n",
    " * В последствии можно испоьзовать более умные способы сбалансировать выборку\n",
    "\n",
    "\n",
    "__Если у вас слабый ПК и вы видите OutOfMemory, попробуйте уменьшить размер выборки до 100 000 примеров__\n",
    "\n",
    "__Алсо если вы не хотите ждать чтения всех данных каждый раз - сохраните уменьшенную выборку и читайте её__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Доля заблокированных объявлений: 0.504583519879\n",
      "Всего объявлений: 544996\n"
     ]
    }
   ],
   "source": [
    "#downsample\n",
    "import random\n",
    "random.seed(26)\n",
    "ind1 = random.sample(df[df.is_blocked==0].itemid, 270000)\n",
    "ind2 = df[df.is_blocked==1].itemid\n",
    "ind1.extend(ind2)\n",
    "df = df[df.itemid.isin(ind1)]\n",
    "\n",
    "print \"Доля заблокированных объявлений:\",df.is_blocked.mean()\n",
    "print \"Всего объявлений:\",len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All tests passed\n"
     ]
    }
   ],
   "source": [
    "assert df.is_blocked.mean() < 0.51\n",
    "assert df.is_blocked.mean() > 0.49\n",
    "assert len(df) <= 560000\n",
    "\n",
    "print \"All tests passed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#прореживаем данные ещё в 2 раза, если памяти не хватает\n",
    "if very_low_ram:\n",
    "    data = data[::2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Токенизируем примеры\n",
    "\n",
    "Сначала соберём словарь всех возможных слов.\n",
    "Поставим каждому слову в соответствие целое число - его id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "from collections import Counter,defaultdict\n",
    "tokenizer = RegexpTokenizer(r\"\\w+\")\n",
    "\n",
    "#словарь для всех токенов\n",
    "token_counts = Counter()\n",
    "\n",
    "#все заголовки и описания\n",
    "all_texts = np.hstack([df.description.values,df.title.values])\n",
    "\n",
    "\n",
    "#считаем частоты слов\n",
    "for s in all_texts:\n",
    "    if type(s) is not str:\n",
    "        continue\n",
    "    s = s.decode('utf8').lower()\n",
    "    tokens = tokenizer.tokenize(s)\n",
    "    for token in tokens:\n",
    "        token_counts[token] +=1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вырежем редкие токены"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAigAAAFkCAYAAAAKf8APAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fcec0dae490>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#распределение частот слов - большинство слов встречаются очень редко - для нас это мусор\n",
    "_=plt.hist(token_counts.values(),range=[0,50],bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#возьмём только те токены, которые встретились хотя бы 10 раз в обучающей выборке\n",
    "#информацию о том, сколько раз встретился каждый токен, можно найти в словаре token_counts\n",
    "\n",
    "min_count = 10\n",
    "tokens = []\n",
    "for token in token_counts.keys():\n",
    "    if token_counts.get(token) >= min_count:\n",
    "        tokens.append(token)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "token_to_id = {t:i+1 for i,t in enumerate(tokens)}\n",
    "null_token = \"NULL\"\n",
    "token_to_id[null_token] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Всего токенов: 87438\n"
     ]
    }
   ],
   "source": [
    "print \"Всего токенов:\",len(token_to_id)\n",
    "if len(token_to_id) < 30000:\n",
    "    print \"Алярм! Мало токенов. Проверьте, есть ли в token_to_id юникодные символы, если нет - обновите nltk или возьмите другой токенизатор\"\n",
    "if len(token_to_id) > 1000000:\n",
    "    print \"Алярм! Много токенов. Если вы знаете, что делаете - всё ок, если нет - возможно, вы слишком слабо обрезали токены по количеству\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Заменим слова на их id\n",
    "Для каждого описания установим максимальную длину. \n",
    " * Если описание больше длины - обрежем, если меньше - дополним нулями.\n",
    " * Таким образом, у нас получится матрица размера (число объявлений)x(максимальная длина)\n",
    " * Элемент под индексами i,j - номер j-того слова i-того объявления"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vectorize(strings, token_to_id, max_len=150):\n",
    "    token_matrix = []\n",
    "    for s in strings:\n",
    "        if type(s) is not str:\n",
    "            token_matrix.append([0]*max_len)\n",
    "            continue\n",
    "        s = s.decode('utf8').lower()\n",
    "        tokens = tokenizer.tokenize(s)\n",
    "        token_ids = map(lambda token: token_to_id.get(token,0), tokens)[:max_len]\n",
    "        token_ids += [0]*(max_len - len(token_ids))\n",
    "        token_matrix.append(token_ids)\n",
    "\n",
    "    return np.array(token_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "desc_tokens = vectorize(df.description.values,token_to_id,max_len = 150)\n",
    "title_tokens = vectorize(df.title.values,token_to_id,max_len = 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Пример формата данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер матрицы: (544996, 15)\n",
      "Костюм Didriksons Boardman, размер 100, краги, шап -> [24664 67208     0 35797 72920 24885     0     0     0     0] ...\n",
      "Поездки на таможню, печать в паспорте -> [42895 14751 55112 81746 79863 17438     0     0     0     0] ...\n",
      "Рефлекторно-урогинекологический массаж -> [ 8410     0 30427     0     0     0     0     0     0     0] ...\n"
     ]
    }
   ],
   "source": [
    "print \"Размер матрицы:\",title_tokens.shape\n",
    "for title, tokens in zip(df.title.values[:3],title_tokens[:3]):\n",
    "    print title,'->', tokens[:10],'...'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__ Как вы видите, всё довольно грязно. Посмотрим, сожрёт ли это нейронка __"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Нетекстовые признаки\n",
    "\n",
    "Часть признаков не являются строками текста: цена, количество телефонов, категория товара.\n",
    "\n",
    "Их можно обработать отдельно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Возьмём числовые признаки\n",
    "df_numerical_features = df[[\"phones_cnt\",\"emails_cnt\",\"urls_cnt\",\"price\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Возьмём one-hot encoding категорий товара.\n",
    "#Для этого можно использовать DictVectorizer (или другой ваш любимый препроцессор)\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "categories = []\n",
    "for cat_str, subcat_str in df[[\"category\",\"subcategory\"]].values:\n",
    "    \n",
    "    cat_dict = {\"category\":cat_str,\"subcategory\":subcat_str}\n",
    "    categories.append(cat_dict)\n",
    "    \n",
    "\n",
    "vectorizer = DictVectorizer(sparse=False)\n",
    "cat_one_hot = vectorizer.fit_transform(categories)\n",
    "cat_one_hot = pd.DataFrame(cat_one_hot,columns=vectorizer.feature_names_)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_non_text = pd.merge(\n",
    "    df_numerical_features,cat_one_hot,on = np.arange(len(cat_one_hot))\n",
    ")\n",
    "del df_non_text[\"key_0\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Поделим данные на обучение и тест"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#целевая переменная - есть заблокирован ли контент\n",
    "target = df.is_blocked.values.astype('int32')\n",
    "#закодированное название\n",
    "title_tokens = title_tokens.astype('int32')\n",
    "#закодированное описание\n",
    "desc_tokens = desc_tokens.astype('int32')\n",
    "\n",
    "#все нетекстовые признаки\n",
    "df_non_text = df_non_text.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#поделим всё это на обучение и тест\n",
    "from sklearn.cross_validation import train_test_split\n",
    "data_tuple = train_test_split(title_tokens,desc_tokens,df_non_text.values,target)\n",
    "\n",
    "title_tr,title_ts,desc_tr,desc_ts,nontext_tr,nontext_ts,target_tr,target_ts = data_tuple\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сохраним данные [опционально] \n",
    "\n",
    "* В этот момент вы можете сохранить все НУЖНЫЕ данные на диск и перезапусатить тетрадку, после чего считать их - чтобы выкинуть всё ненужное.\n",
    " * рекомендуется, если у вас мало памяти\n",
    "* Для этого нужно один раз выполнить эту клетку с save_prepared_data=True. После этого можно начинать тетрадку с ЭТОЙ табы в режиме read_prepared_data=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Сохраняем подготовленные данные... (может занять до 3 минут)\n",
      "готово\n"
     ]
    }
   ],
   "source": [
    "\n",
    "save_prepared_data = False #сохранить\n",
    "read_prepared_data = True #cчитать\n",
    "\n",
    "#за 1 раз данные можно либо записать, либо прочитать, но не и то и другое вместе\n",
    "assert not (save_prepared_data and read_prepared_data)\n",
    "\n",
    "\n",
    "if save_prepared_data:\n",
    "    print \"Сохраняем подготовленные данные... (может занять до 3 минут)\"\n",
    "\n",
    "    import pickle\n",
    "    with open(\"preprocessed_data.pcl\",'w') as fout:\n",
    "        pickle.dump(data_tuple,fout)\n",
    "    with open(\"token_to_id.pcl\",'w') as fout:\n",
    "        pickle.dump(token_to_id,fout)\n",
    "\n",
    "    print \"готово\"\n",
    "    \n",
    "elif read_prepared_data:\n",
    "    print \"Читаем сохранённые данные...\"\n",
    "    \n",
    "    import pickle\n",
    "    \n",
    "    with open(\"preprocessed_data.pcl\",'r') as fin:\n",
    "        data_tuple = pickle.load(fin)\n",
    "    title_tr,title_ts,desc_tr,desc_ts,nontext_tr,nontext_ts,target_tr,target_ts = data_tuple\n",
    "    with open(\"token_to_id.pcl\",'r') as fin:\n",
    "        token_to_id = pickle.load(fin)\n",
    "\n",
    "\n",
    "        \n",
    "    #повторно импортируем библиотеки, чтобы было удобно перезапускать тетрадку с этой клетки\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    %matplotlib inline\n",
    "\n",
    "        \n",
    "    print \"готово\"\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Поучим нейронку\n",
    "\n",
    "Поскольку у нас есть несколько источников данных, наша нейронная сеть будет немного отличаться от тех, что вы тренировали раньше.\n",
    "\n",
    "* Отдельный вход для заголовка\n",
    " * свёртка + global max pool или RNN\n",
    "* Отдельный вход для описания\n",
    " * свёртка + global max pool или RNN\n",
    "* Отдельный вход для категориальных признаков\n",
    " * обычные полносвязные слои или какие-нибудь трюки\n",
    " \n",
    "Всё это нужно как-то смешать - например, сконкатенировать\n",
    "\n",
    "* Выход - обычный двухклассовый выход\n",
    " * 1 сигмоидальный нейрон и binary_crossentropy\n",
    " * 2 нейрона с softmax и categorical_crossentropy - то же самое, что 1 сигмоидальный\n",
    " * 1 нейрон без нелинейности (lambda x: x) и hinge loss\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#загрузим библиотеки\n",
    "import lasagne\n",
    "from theano import tensor as T\n",
    "import theano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#3 входа и 1 выход\n",
    "title_token_ids = T.matrix(\"title_token_ids\",dtype='int32')\n",
    "desc_token_ids = T.matrix(\"desc_token_ids\",dtype='int32')\n",
    "categories = T.matrix(\"categories\",dtype='float32')\n",
    "target_y = T.ivector(\"is_blocked\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Архитектура нейронной сети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "title_inp = lasagne.layers.InputLayer((None,title_tr.shape[1]),input_var=title_token_ids)\n",
    "descr_inp = lasagne.layers.InputLayer((None,desc_tr.shape[1]),input_var=desc_token_ids)\n",
    "cat_inp = lasagne.layers.InputLayer((None,nontext_tr.shape[1]), input_var=categories)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Описание\n",
    "descr_nn = lasagne.layers.EmbeddingLayer(descr_inp,input_size=len(token_to_id)+1,output_size=128)\n",
    "\n",
    "#поменять порядок осей с [batch, time, unit] на [batch,unit,time], чтобы свёртки шли по оси времени, а не по нейронам\n",
    "descr_nn = lasagne.layers.DimshuffleLayer(descr_nn, [0,2,1])\n",
    "\n",
    "# 1D свёртка на ваш вкус\n",
    "descr_nn = lasagne.layers.Conv1DLayer(descr_nn,num_filters=16,filter_size=3)\n",
    "\n",
    "# максимум по времени для каждого нейрона\n",
    "descr_nn = lasagne.layers.GlobalPoolLayer(descr_nn,pool_function=T.max)\n",
    "\n",
    "#А ещё можно делать несколько параллельных свёрток разного размера или стандартный пайплайн \n",
    "#1dconv -> 1d max pool ->1dconv и в конце global pool \n",
    "\n",
    "\n",
    "# Заголовок\n",
    "title_nn = lasagne.layers.EmbeddingLayer(title_inp,input_size=len(token_to_id)+1,output_size=8)\n",
    "title_nn = lasagne.layers.DimshuffleLayer(title_nn, [0,2,1])\n",
    "title_nn = lasagne.layers.Conv1DLayer(title_nn,num_filters=4,filter_size=2)\n",
    "title_nn = lasagne.layers.GlobalPoolLayer(title_nn,T.max)\n",
    "\n",
    "# Нетекстовые признаки\n",
    "cat_nn = lasagne.layers.DenseLayer(cat_inp, num_units=32,nonlinearity=lasagne.nonlinearities.rectify)\n",
    "cat_nn = lasagne.layers.DropoutLayer(cat_nn, p=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nn = lasagne.layers.concat([descr_nn, title_nn, cat_nn])                                 \n",
    "\n",
    "nn = lasagne.layers.DenseLayer(nn,1024)\n",
    "nn = lasagne.layers.DropoutLayer(nn,p=0.05)\n",
    "nn = lasagne.layers.DenseLayer(nn,1,nonlinearity=lasagne.nonlinearities.linear)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Целевая функция и обновления весов\n",
    "\n",
    "* Делаем всё стандартно:\n",
    " * получаем предсказание\n",
    " * считаем функцию потерь\n",
    " * вычисляем обновления весов\n",
    " * компилируем итерацию обучения и оценки весов\n",
    " \n",
    " \n",
    "* Hinge loss\n",
    " * $ L_i = \\max(0, \\delta - t_i p_i) $\n",
    " * Важный параметр - delta - насколько глубоко пример должен быть в правильном классе, чтобы перестать нас волновать\n",
    " * В описании функции в документации может быть что-то про ограничения на +-1 - не верьте этому - главное, чтобы в функции по умолчанию стоял флаг `binary = True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Все обучаемые параметры сети\n",
    "weights = lasagne.layers.get_all_params(nn,trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Обычное предсказание нейронки\n",
    "prediction = lasagne.layers.get_output(nn)[:,0]\n",
    "\n",
    "#функция потерь для prediction\n",
    "loss = lasagne.objectives.binary_hinge_loss(prediction,target_y,delta = 1.0).mean()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Шаг оптимизации весов\n",
    "updates = lasagne.updates.adam(loss, weights, learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Чтобы оценивать качество сети, в которой есть элемент случайности \n",
    " * Dropout, например,\n",
    " * Нужно отдельно вычислить ошибку для случая, когда dropout выключен (deterministic = True)\n",
    " * К слову, неплохо бы убедиться, что droput нам вообще нужен"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Предсказание нейронки без учёта dropout и прочего шума - если он есть\n",
    "det_prediction = lasagne.layers.get_output(nn,deterministic=True)[:,0]\n",
    "\n",
    "#функция потерь для det_prediction\n",
    "det_loss = lasagne.objectives.binary_hinge_loss(det_prediction,target_y,delta = 1.0).mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Скомпилируем функции обучения и оценки качества"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO (theano.gof.compilelock): Waiting for existing lock by process '12823' (I am process '13916')\n",
      "INFO (theano.gof.compilelock): To manually release the lock, delete /home/timur/.theano/compiledir_Linux-4.4--generic-x86_64-with-debian-jessie-sid-x86_64-2.7.12-64/lock_dir\n"
     ]
    }
   ],
   "source": [
    "train_fun = theano.function([desc_token_ids,title_token_ids,categories,target_y],[loss,prediction],updates = updates)\n",
    "eval_fun = theano.function([desc_token_ids,title_token_ids,categories,target_y],[det_loss,det_prediction])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Главный цикл обучения\n",
    "* Всё как обычно - в цикле по минибатчам запускаем функцию обновления весов.\n",
    "* Поскольку выборка огромна, а чашки чая хватает в среднем на  100к примеров, будем на каждой эпохе пробегать только часть примеров."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#average precision at K\n",
    "\n",
    "from oracle import APatK, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# наш старый знакомый - итератор по корзинкам - теперь умеет работать с произвольным числом каналов (название, описание, категории, таргет)\n",
    "\n",
    "def iterate_minibatches(*arrays,**kwargs):\n",
    "    \n",
    "    batchsize=kwargs.get(\"batchsize\",100)\n",
    "    shuffle = kwargs.get(\"shuffle\",True)\n",
    "    \n",
    "    if shuffle:\n",
    "        indices = np.arange(len(arrays[0]))\n",
    "        np.random.shuffle(indices)\n",
    "    for start_idx in range(0, len(arrays[0]) - batchsize + 1, batchsize):\n",
    "        if shuffle:\n",
    "            excerpt = indices[start_idx:start_idx + batchsize]\n",
    "        else:\n",
    "            excerpt = slice(start_idx, start_idx + batchsize)\n",
    "        yield [arr[excerpt] for arr in arrays]\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "\tloss: 6957.95211109\n",
      "\tacc: 0.608217821782\n",
      "\tauc: 0.66082404009\n",
      "\tap@k: 0.116190922985\n",
      "Val:\n",
      "\tloss: 3530.8686273\n",
      "\tacc: 0.709108910891\n",
      "\tauc: 0.806175565819\n",
      "\tap@k: 0.978275640192\n",
      "Train:\n",
      "\tloss: 423.204356256\n",
      "\tacc: 0.707128712871\n",
      "\tauc: 0.758612213371\n",
      "\tap@k: 0.24408686404\n",
      "Val:\n",
      "\tloss: 96.1215669558\n",
      "\tacc: 0.70297029703\n",
      "\tauc: 0.77413183083\n",
      "\tap@k: 0.862274655306\n",
      "Train:\n",
      "\tloss: 471.605051693\n",
      "\tacc: 0.769801980198\n",
      "\tauc: 0.819772078371\n",
      "\tap@k: 0.105942427466\n",
      "Val:\n",
      "\tloss: 452.22197734\n",
      "\tacc: 0.805742574257\n",
      "\tauc: 0.905456166481\n",
      "\tap@k: 0.979784060504\n",
      "Train:\n",
      "\tloss: 4.15664039391\n",
      "\tacc: 0.842475247525\n",
      "\tauc: 0.905745832594\n",
      "\tap@k: 0.978933268853\n",
      "Val:\n",
      "\tloss: 0.696114015372\n",
      "\tacc: 0.876435643564\n",
      "\tauc: 0.954401119423\n",
      "\tap@k: 0.991432702812\n",
      "Train:\n",
      "\tloss: 0.817923240524\n",
      "\tacc: 0.86297029703\n",
      "\tauc: 0.919367628145\n",
      "\tap@k: 0.989350184979\n",
      "Val:\n",
      "\tloss: 0.878318786901\n",
      "\tacc: 0.867722772277\n",
      "\tauc: 0.951075146263\n",
      "\tap@k: 0.971166661229\n",
      "Train:\n",
      "\tloss: 0.675243419728\n",
      "\tacc: 0.88099009901\n",
      "\tauc: 0.929994474876\n",
      "\tap@k: 0.985267933538\n",
      "Val:\n",
      "\tloss: 0.3741286862\n",
      "\tacc: 0.907425742574\n",
      "\tauc: 0.956524533486\n",
      "\tap@k: 0.994650969892\n",
      "Train:\n",
      "\tloss: 0.468629823803\n",
      "\tacc: 0.883267326733\n",
      "\tauc: 0.933990423117\n",
      "\tap@k: 0.99591664296\n",
      "Val:\n",
      "\tloss: 0.294245304999\n",
      "\tacc: 0.910297029703\n",
      "\tauc: 0.958662582223\n",
      "\tap@k: 0.99188108719\n",
      "Train:\n",
      "\tloss: 0.432323622767\n",
      "\tacc: 0.894554455446\n",
      "\tauc: 0.942163296197\n",
      "\tap@k: 1.0\n",
      "Val:\n",
      "\tloss: 0.253107217539\n",
      "\tacc: 0.918415841584\n",
      "\tauc: 0.967783269611\n",
      "\tap@k: 1.0\n",
      "Train:\n",
      "\tloss: 0.304617924955\n",
      "\tacc: 0.911386138614\n",
      "\tauc: 0.955988079807\n",
      "\tap@k: 0.986651088551\n",
      "Val:\n",
      "\tloss: 0.235142149893\n",
      "\tacc: 0.921188118812\n",
      "\tauc: 0.972379203866\n",
      "\tap@k: 0.986834182822\n",
      "Train:\n",
      "\tloss: 1.75762137469\n",
      "\tacc: 0.902871287129\n",
      "\tauc: 0.950392033557\n",
      "\tap@k: 0.961854416304\n",
      "Val:\n",
      "\tloss: 0.228551313613\n",
      "\tacc: 0.924851485149\n",
      "\tauc: 0.972400367537\n",
      "\tap@k: 0.998635620671\n",
      "Train:\n",
      "\tloss: 0.269986816688\n",
      "\tacc: 0.920396039604\n",
      "\tauc: 0.967545470546\n",
      "\tap@k: 0.976081626657\n",
      "Val:\n",
      "\tloss: 0.19025643102\n",
      "\tacc: 0.935742574257\n",
      "\tauc: 0.979348438471\n",
      "\tap@k: 0.994528402243\n",
      "Train:\n",
      "\tloss: 0.228158433067\n",
      "\tacc: 0.926138613861\n",
      "\tauc: 0.972186639843\n",
      "\tap@k: 0.989542848934\n",
      "Val:\n",
      "\tloss: 0.202745486036\n",
      "\tacc: 0.931386138614\n",
      "\tauc: 0.979527362989\n",
      "\tap@k: 1.0\n",
      "Train:\n",
      "\tloss: 0.197110142744\n",
      "\tacc: 0.93504950495\n",
      "\tauc: 0.977270509115\n",
      "\tap@k: 0.996057714351\n",
      "Val:\n",
      "\tloss: 0.185425349643\n",
      "\tacc: 0.931683168317\n",
      "\tauc: 0.981228507457\n",
      "\tap@k: 0.999725630362\n",
      "Train:\n",
      "\tloss: 0.215339174254\n",
      "\tacc: 0.929405940594\n",
      "\tauc: 0.975631830673\n",
      "\tap@k: 0.995609402906\n",
      "Val:\n",
      "\tloss: 0.18329088861\n",
      "\tacc: 0.937920792079\n",
      "\tauc: 0.980311832479\n",
      "\tap@k: 1.0\n",
      "Train:\n",
      "\tloss: 0.174795991807\n",
      "\tacc: 0.942178217822\n",
      "\tauc: 0.981353395099\n",
      "\tap@k: 0.996576248784\n",
      "Val:\n",
      "\tloss: 0.176279913345\n",
      "\tacc: 0.939306930693\n",
      "\tauc: 0.981021809414\n",
      "\tap@k: 0.999775453248\n",
      "Train:\n",
      "\tloss: 0.17750621721\n",
      "\tacc: 0.938514851485\n",
      "\tauc: 0.981194810187\n",
      "\tap@k: 1.0\n",
      "Val:\n",
      "\tloss: 0.161145942292\n",
      "\tacc: 0.944851485149\n",
      "\tauc: 0.984286931043\n",
      "\tap@k: 0.999519810524\n",
      "Train:\n",
      "\tloss: 0.146586483892\n",
      "\tacc: 0.946138613861\n",
      "\tauc: 0.985024255576\n",
      "\tap@k: 1.0\n",
      "Val:\n",
      "\tloss: 0.162253043506\n",
      "\tacc: 0.941089108911\n",
      "\tauc: 0.983020801178\n",
      "\tap@k: 0.997582061856\n",
      "Train:\n",
      "\tloss: 0.585517580188\n",
      "\tacc: 0.93801980198\n",
      "\tauc: 0.979401655792\n",
      "\tap@k: 0.997314493898\n",
      "Val:\n",
      "\tloss: 0.181896251845\n",
      "\tacc: 0.939702970297\n",
      "\tauc: 0.983242964557\n",
      "\tap@k: 1.0\n",
      "Train:\n",
      "\tloss: 0.160805420643\n",
      "\tacc: 0.945643564356\n",
      "\tauc: 0.981716641194\n",
      "\tap@k: 1.0\n",
      "Val:\n",
      "\tloss: 0.161733681661\n",
      "\tacc: 0.940693069307\n",
      "\tauc: 0.98184796579\n",
      "\tap@k: 0.998786829904\n",
      "Train:\n",
      "\tloss: 1.09357550372\n",
      "\tacc: 0.946633663366\n",
      "\tauc: 0.98362451905\n",
      "\tap@k: 0.860643301982\n",
      "Val:\n",
      "\tloss: 0.146593399993\n",
      "\tacc: 0.945346534653\n",
      "\tauc: 0.984883416139\n",
      "\tap@k: 1.0\n",
      "Train:\n",
      "\tloss: 0.128726694968\n",
      "\tacc: 0.952376237624\n",
      "\tauc: 0.987212541473\n",
      "\tap@k: 1.0\n",
      "Val:\n",
      "\tloss: 0.153824042975\n",
      "\tacc: 0.943861386139\n",
      "\tauc: 0.98419574251\n",
      "\tap@k: 0.99436841896\n",
      "Train:\n",
      "\tloss: 0.126182529379\n",
      "\tacc: 0.95504950495\n",
      "\tauc: 0.987514690531\n",
      "\tap@k: 0.994769850874\n",
      "Val:\n",
      "\tloss: 0.135419365385\n",
      "\tacc: 0.950594059406\n",
      "\tauc: 0.98694290967\n",
      "\tap@k: 1.0\n",
      "Train:\n",
      "\tloss: 0.132817169534\n",
      "\tacc: 0.95\n",
      "\tauc: 0.986065455585\n",
      "\tap@k: 0.995514801667\n",
      "Val:\n",
      "\tloss: 0.143054718385\n",
      "\tacc: 0.946138613861\n",
      "\tauc: 0.985781574022\n",
      "\tap@k: 1.0\n",
      "Train:\n",
      "\tloss: 0.128799088497\n",
      "\tacc: 0.951188118812\n",
      "\tauc: 0.986896168151\n",
      "\tap@k: 0.996303546962\n",
      "Val:\n",
      "\tloss: 0.130097199177\n",
      "\tacc: 0.950297029703\n",
      "\tauc: 0.987197211441\n",
      "\tap@k: 0.993375697293\n",
      "Train:\n",
      "\tloss: 0.128266487506\n",
      "\tacc: 0.952772277228\n",
      "\tauc: 0.985652329793\n",
      "\tap@k: 0.997939132223\n",
      "Val:\n",
      "\tloss: 0.118237579855\n",
      "\tacc: 0.954158415842\n",
      "\tauc: 0.988681010583\n",
      "\tap@k: 1.0\n",
      "Train:\n",
      "\tloss: 0.11511958488\n",
      "\tacc: 0.956930693069\n",
      "\tauc: 0.988534456752\n",
      "\tap@k: 0.996343072653\n",
      "Val:\n",
      "\tloss: 0.136252579116\n",
      "\tacc: 0.947227722772\n",
      "\tauc: 0.98544213672\n",
      "\tap@k: 0.995064625271\n",
      "Train:\n",
      "\tloss: 0.115227882489\n",
      "\tacc: 0.955148514851\n",
      "\tauc: 0.989142276337\n",
      "\tap@k: 0.994465663049\n",
      "Val:\n",
      "\tloss: 0.126094420248\n",
      "\tacc: 0.948811881188\n",
      "\tauc: 0.987562357071\n",
      "\tap@k: 1.0\n",
      "Train:\n",
      "\tloss: 0.10268438054\n",
      "\tacc: 0.959900990099\n",
      "\tauc: 0.990673214663\n",
      "\tap@k: 1.0\n",
      "Val:\n",
      "\tloss: 0.124315416836\n",
      "\tacc: 0.950396039604\n",
      "\tauc: 0.986986988282\n",
      "\tap@k: 0.997599710419\n",
      "Train:\n",
      "\tloss: 0.108828840715\n",
      "\tacc: 0.958415841584\n",
      "\tauc: 0.988852381867\n",
      "\tap@k: 1.0\n",
      "Val:\n",
      "\tloss: 0.121365591419\n",
      "\tacc: 0.952079207921\n",
      "\tauc: 0.988257769514\n",
      "\tap@k: 0.998143841029\n",
      "Train:\n",
      "\tloss: 0.0990786195366\n",
      "\tacc: 0.961287128713\n",
      "\tauc: 0.990460593394\n",
      "\tap@k: 1.0\n",
      "Val:\n",
      "\tloss: 0.128459644911\n",
      "\tacc: 0.950099009901\n",
      "\tauc: 0.986789324833\n",
      "\tap@k: 1.0\n",
      "Train:\n",
      "\tloss: 0.107309822565\n",
      "\tacc: 0.959306930693\n",
      "\tauc: 0.988757747246\n",
      "\tap@k: 1.0\n",
      "Val:\n",
      "\tloss: 0.123271606984\n",
      "\tacc: 0.951386138614\n",
      "\tauc: 0.987121374457\n",
      "\tap@k: 1.0\n",
      "Train:\n",
      "\tloss: 0.103386274974\n",
      "\tacc: 0.959801980198\n",
      "\tauc: 0.989684025019\n",
      "\tap@k: 1.0\n",
      "Val:\n",
      "\tloss: 0.117419179939\n",
      "\tacc: 0.955643564356\n",
      "\tauc: 0.988070910406\n",
      "\tap@k: 1.0\n",
      "Train:\n",
      "\tloss: 0.0910263156129\n",
      "\tacc: 0.964356435644\n",
      "\tauc: 0.991451779165\n",
      "\tap@k: 1.0\n",
      "Val:\n",
      "\tloss: 0.118495279668\n",
      "\tacc: 0.952376237624\n",
      "\tauc: 0.986230229539\n",
      "\tap@k: 1.0\n",
      "Train:\n",
      "\tloss: 0.569544248467\n",
      "\tacc: 0.962277227723\n",
      "\tauc: 0.98953151239\n",
      "\tap@k: 0.89231566337\n",
      "Val:\n",
      "\tloss: 0.155541267437\n",
      "\tacc: 0.949603960396\n",
      "\tauc: 0.988132097371\n",
      "\tap@k: 0.994999242267\n",
      "Train:\n",
      "\tloss: 0.0986801739348\n",
      "\tacc: 0.962772277228\n",
      "\tauc: 0.990785025966\n",
      "\tap@k: 1.0\n",
      "Val:\n",
      "\tloss: 0.116722241743\n",
      "\tacc: 0.953762376238\n",
      "\tauc: 0.988098297276\n",
      "\tap@k: 1.0\n",
      "Train:\n",
      "\tloss: 0.0848310217732\n",
      "\tacc: 0.967425742574\n",
      "\tauc: 0.992469059181\n",
      "\tap@k: 1.0\n",
      "Val:\n",
      "\tloss: 0.111806997194\n",
      "\tacc: 0.95702970297\n",
      "\tauc: 0.988241655592\n",
      "\tap@k: 0.975839604204\n",
      "Train:\n",
      "\tloss: 0.083636719613\n",
      "\tacc: 0.96702970297\n",
      "\tauc: 0.992576242627\n",
      "\tap@k: 0.998613539279\n",
      "Val:\n",
      "\tloss: 0.107960442954\n",
      "\tacc: 0.957128712871\n",
      "\tauc: 0.989752779854\n",
      "\tap@k: 1.0\n",
      "Train:\n",
      "\tloss: 0.086530599629\n",
      "\tacc: 0.966633663366\n",
      "\tauc: 0.990844020231\n",
      "\tap@k: 0.999284037386\n",
      "Val:\n",
      "\tloss: 0.118797097079\n",
      "\tacc: 0.952772277228\n",
      "\tauc: 0.988001597238\n",
      "\tap@k: 1.0\n",
      "Train:\n",
      "\tloss: 0.084929568867\n",
      "\tacc: 0.968415841584\n",
      "\tauc: 0.991349062161\n",
      "\tap@k: 0.978745014453\n",
      "Val:\n",
      "\tloss: 0.108254161314\n",
      "\tacc: 0.956831683168\n",
      "\tauc: 0.988738157886\n",
      "\tap@k: 0.999284037386\n",
      "Train:\n",
      "\tloss: 0.0905224854049\n",
      "\tacc: 0.963366336634\n",
      "\tauc: 0.9910997304\n",
      "\tap@k: 0.999758915302\n",
      "Val:\n",
      "\tloss: 0.126955981207\n",
      "\tacc: 0.951782178218\n",
      "\tauc: 0.987532417901\n",
      "\tap@k: 0.997060427474\n",
      "Train:\n",
      "\tloss: 0.0861144768218\n",
      "\tacc: 0.965742574257\n",
      "\tauc: 0.991961174097\n",
      "\tap@k: 0.995371326718\n",
      "Val:\n",
      "\tloss: 0.105919415251\n",
      "\tacc: 0.958613861386\n",
      "\tauc: 0.987758207297\n",
      "\tap@k: 1.0\n",
      "Train:\n",
      "\tloss: 0.0825995210074\n",
      "\tacc: 0.966435643564\n",
      "\tauc: 0.991647861093\n",
      "\tap@k: 0.998635620671\n",
      "Val:\n",
      "\tloss: 0.0962082834071\n",
      "\tacc: 0.961782178218\n",
      "\tauc: 0.990630182525\n",
      "\tap@k: 0.999775453248\n",
      "Train:\n",
      "\tloss: 0.0835404001321\n",
      "\tacc: 0.96702970297\n",
      "\tauc: 0.992130213751\n",
      "\tap@k: 1.0\n",
      "Val:\n",
      "\tloss: 0.107908209198\n",
      "\tacc: 0.955940594059\n",
      "\tauc: 0.989556197409\n",
      "\tap@k: 1.0\n",
      "Train:\n",
      "\tloss: 0.0765733437117\n",
      "\tacc: 0.970396039604\n",
      "\tauc: 0.992335715533\n",
      "\tap@k: 0.996223289682\n",
      "Val:\n",
      "\tloss: 0.100232798767\n",
      "\tacc: 0.957227722772\n",
      "\tauc: 0.989307676746\n",
      "\tap@k: 1.0\n",
      "Train:\n",
      "\tloss: 0.0771405947505\n",
      "\tacc: 0.968613861386\n",
      "\tauc: 0.992231331827\n",
      "\tap@k: 1.0\n",
      "Val:\n",
      "\tloss: 0.11129327445\n",
      "\tacc: 0.954554455446\n",
      "\tauc: 0.988826471716\n",
      "\tap@k: 0.997435654337\n",
      "Train:\n",
      "\tloss: 0.0755371660041\n",
      "\tacc: 0.971188118812\n",
      "\tauc: 0.99116282763\n",
      "\tap@k: 1.0\n",
      "Val:\n",
      "\tloss: 0.091955197869\n",
      "\tacc: 0.961881188119\n",
      "\tauc: 0.991023672077\n",
      "\tap@k: 0.997283614452\n",
      "Train:\n",
      "\tloss: 0.0849149362753\n",
      "\tacc: 0.966336633663\n",
      "\tauc: 0.990479194481\n",
      "\tap@k: 1.0\n",
      "Val:\n",
      "\tloss: 0.101414638356\n",
      "\tacc: 0.956732673267\n",
      "\tauc: 0.989520034994\n",
      "\tap@k: 1.0\n",
      "Train:\n",
      "\tloss: 0.0754731349437\n",
      "\tacc: 0.969603960396\n",
      "\tauc: 0.992573156873\n",
      "\tap@k: 0.96839028356\n",
      "Val:\n",
      "\tloss: 0.0954591457439\n",
      "\tacc: 0.96099009901\n",
      "\tauc: 0.989461969252\n",
      "\tap@k: 0.995559685701\n",
      "Train:\n",
      "\tloss: 0.0682599947266\n",
      "\tacc: 0.972871287129\n",
      "\tauc: 0.993260357433\n",
      "\tap@k: 0.999189473985\n",
      "Val:\n",
      "\tloss: 0.0951559004619\n",
      "\tacc: 0.960693069307\n",
      "\tauc: 0.988844593906\n",
      "\tap@k: 0.9994844406\n",
      "Train:\n",
      "\tloss: 0.0685802416284\n",
      "\tacc: 0.972079207921\n",
      "\tauc: 0.993764116224\n",
      "\tap@k: 1.0\n",
      "Val:\n",
      "\tloss: 0.106161656244\n",
      "\tacc: 0.956534653465\n",
      "\tauc: 0.988431155313\n",
      "\tap@k: 1.0\n",
      "Train:\n",
      "\tloss: 0.067976152583\n",
      "\tacc: 0.97396039604\n",
      "\tauc: 0.991840920739\n",
      "\tap@k: 1.0\n",
      "Val:\n",
      "\tloss: 0.0956095433439\n",
      "\tacc: 0.961683168317\n",
      "\tauc: 0.989148813753\n",
      "\tap@k: 1.0\n",
      "Train:\n",
      "\tloss: 0.0625988266099\n",
      "\tacc: 0.975148514851\n",
      "\tauc: 0.994121352352\n",
      "\tap@k: 0.989051428378\n",
      "Val:\n",
      "\tloss: 0.0971371664372\n",
      "\tacc: 0.960495049505\n",
      "\tauc: 0.988910755226\n",
      "\tap@k: 1.0\n",
      "Train:\n",
      "\tloss: 0.0660660851635\n",
      "\tacc: 0.973168316832\n",
      "\tauc: 0.993700457631\n",
      "\tap@k: 1.0\n",
      "Val:\n",
      "\tloss: 0.102960657878\n",
      "\tacc: 0.958613861386\n",
      "\tauc: 0.988248861248\n",
      "\tap@k: 1.0\n",
      "Train:\n",
      "\tloss: 0.0769020765138\n",
      "\tacc: 0.968910891089\n",
      "\tauc: 0.991353089398\n",
      "\tap@k: 1.0\n",
      "Val:\n",
      "\tloss: 0.094035467702\n",
      "\tacc: 0.961485148515\n",
      "\tauc: 0.989413312624\n",
      "\tap@k: 0.997021153266\n",
      "Train:\n",
      "\tloss: 0.0612351456597\n",
      "\tacc: 0.974059405941\n",
      "\tauc: 0.994840174462\n",
      "\tap@k: 1.0\n",
      "Val:\n",
      "\tloss: 0.0983032748144\n",
      "\tacc: 0.959801980198\n",
      "\tauc: 0.989726153103\n",
      "\tap@k: 1.0\n",
      "Train:\n",
      "\tloss: 0.0708324442506\n",
      "\tacc: 0.971683168317\n",
      "\tauc: 0.992110525119\n",
      "\tap@k: 1.0\n",
      "Val:\n",
      "\tloss: 0.100370028357\n",
      "\tacc: 0.958316831683\n",
      "\tauc: 0.989004075517\n",
      "\tap@k: 1.0\n",
      "Train:\n",
      "\tloss: 0.0692093118306\n",
      "\tacc: 0.973366336634\n",
      "\tauc: 0.992180716172\n",
      "\tap@k: 0.996645807276\n",
      "Val:\n",
      "\tloss: 0.0976215438406\n",
      "\tacc: 0.960792079208\n",
      "\tauc: 0.988652838943\n",
      "\tap@k: 0.994636647265\n",
      "Train:\n",
      "\tloss: 0.0625158100577\n",
      "\tacc: 0.974653465347\n",
      "\tauc: 0.99340934326\n",
      "\tap@k: 1.0\n",
      "Val:\n",
      "\tloss: 0.0986671094368\n",
      "\tacc: 0.958910891089\n",
      "\tauc: 0.990269383354\n",
      "\tap@k: 1.0\n",
      "Train:\n",
      "\tloss: 0.0691400448245\n",
      "\tacc: 0.971881188119\n",
      "\tauc: 0.993327567363\n",
      "\tap@k: 1.0\n",
      "Val:\n",
      "\tloss: 0.108991887024\n",
      "\tacc: 0.956435643564\n",
      "\tauc: 0.98571698429\n",
      "\tap@k: 1.0\n",
      "Train:\n",
      "\tloss: 0.0673141143111\n",
      "\tacc: 0.972673267327\n",
      "\tauc: 0.992625581658\n",
      "\tap@k: 0.999448751306\n",
      "Val:\n",
      "\tloss: 0.0989585296244\n",
      "\tacc: 0.960594059406\n",
      "\tauc: 0.989699551726\n",
      "\tap@k: 0.999775453248\n",
      "Train:\n",
      "\tloss: 0.062677730678\n",
      "\tacc: 0.974158415842\n",
      "\tauc: 0.994181311615\n",
      "\tap@k: 1.0\n",
      "Val:\n",
      "\tloss: 0.106152083804\n",
      "\tacc: 0.956633663366\n",
      "\tauc: 0.988406705459\n",
      "\tap@k: 0.997314493898\n",
      "Train:\n",
      "\tloss: 0.0574416896214\n",
      "\tacc: 0.976534653465\n",
      "\tauc: 0.993744995273\n",
      "\tap@k: 0.998870707001\n",
      "Val:\n",
      "\tloss: 0.100266876849\n",
      "\tacc: 0.958811881188\n",
      "\tauc: 0.988039188861\n",
      "\tap@k: 0.997531964724\n",
      "Train:\n",
      "\tloss: 0.0642813703952\n",
      "\tacc: 0.97396039604\n",
      "\tauc: 0.992172432658\n",
      "\tap@k: 0.996254664924\n",
      "Val:\n",
      "\tloss: 0.095173380335\n",
      "\tacc: 0.962376237624\n",
      "\tauc: 0.991158330468\n",
      "\tap@k: 1.0\n",
      "Train:\n",
      "\tloss: 0.0681353773251\n",
      "\tacc: 0.973069306931\n",
      "\tauc: 0.992219625849\n",
      "\tap@k: 1.0\n",
      "Val:\n",
      "\tloss: 0.109420897473\n",
      "\tacc: 0.956732673267\n",
      "\tauc: 0.988328079397\n",
      "\tap@k: 0.991186547901\n",
      "Train:\n",
      "\tloss: 0.0567168700321\n",
      "\tacc: 0.978415841584\n",
      "\tauc: 0.99352420077\n",
      "\tap@k: 0.995607898014\n",
      "Val:\n",
      "\tloss: 0.0976054300283\n",
      "\tacc: 0.959306930693\n",
      "\tauc: 0.989372645823\n",
      "\tap@k: 0.999937134834\n",
      "Train:\n",
      "\tloss: 0.0632113851213\n",
      "\tacc: 0.974158415842\n",
      "\tauc: 0.994105575661\n",
      "\tap@k: 1.0\n",
      "Val:\n",
      "\tloss: 0.0958296184249\n",
      "\tacc: 0.958910891089\n",
      "\tauc: 0.990051944664\n",
      "\tap@k: 0.999758915302\n",
      "Train:\n",
      "\tloss: 0.0657186509057\n",
      "\tacc: 0.973267326733\n",
      "\tauc: 0.992584580275\n",
      "\tap@k: 0.998828990941\n",
      "Val:\n",
      "\tloss: 0.0966389747773\n",
      "\tacc: 0.959108910891\n",
      "\tauc: 0.989090805362\n",
      "\tap@k: 0.990059919055\n",
      "Train:\n",
      "\tloss: 0.0626124671505\n",
      "\tacc: 0.974356435644\n",
      "\tauc: 0.993226556167\n",
      "\tap@k: 0.998722732939\n",
      "Val:\n",
      "\tloss: 0.0935376377495\n",
      "\tacc: 0.962376237624\n",
      "\tauc: 0.990926524856\n",
      "\tap@k: 0.99836213583\n",
      "Train:\n",
      "\tloss: 0.0623865828553\n",
      "\tacc: 0.974257425743\n",
      "\tauc: 0.993149484452\n",
      "\tap@k: 0.992160404973\n",
      "Val:\n",
      "\tloss: 0.0886007818919\n",
      "\tacc: 0.96297029703\n",
      "\tauc: 0.991316364319\n",
      "\tap@k: 1.0\n",
      "Train:\n",
      "\tloss: 0.0579452341193\n",
      "\tacc: 0.975445544554\n",
      "\tauc: 0.994666368966\n",
      "\tap@k: 1.0\n",
      "Val:\n",
      "\tloss: 0.091178029785\n",
      "\tacc: 0.96297029703\n",
      "\tauc: 0.988268249996\n",
      "\tap@k: 0.999775453248\n",
      "Train:\n",
      "\tloss: 0.0572464171523\n",
      "\tacc: 0.976732673267\n",
      "\tauc: 0.993571016146\n",
      "\tap@k: 1.0\n",
      "Val:\n",
      "\tloss: 0.0882542490508\n",
      "\tacc: 0.962673267327\n",
      "\tauc: 0.990174096325\n",
      "\tap@k: 0.994401911934\n",
      "Train:\n",
      "\tloss: 0.0550340288358\n",
      "\tacc: 0.97702970297\n",
      "\tauc: 0.992981039958\n",
      "\tap@k: 0.994447515025\n",
      "Val:\n",
      "\tloss: 0.0871574290172\n",
      "\tacc: 0.964356435644\n",
      "\tauc: 0.989732781473\n",
      "\tap@k: 0.987598057152\n",
      "Train:\n",
      "\tloss: 0.0562119105146\n",
      "\tacc: 0.977326732673\n",
      "\tauc: 0.993171574035\n",
      "\tap@k: 1.0\n",
      "Val:\n",
      "\tloss: 0.0900613860618\n",
      "\tacc: 0.962475247525\n",
      "\tauc: 0.989882716026\n",
      "\tap@k: 0.990389443011\n",
      "Train:\n",
      "\tloss: 0.05652878663\n",
      "\tacc: 0.977425742574\n",
      "\tauc: 0.992594207448\n",
      "\tap@k: 1.0\n",
      "Val:\n",
      "\tloss: 0.094723231953\n",
      "\tacc: 0.961386138614\n",
      "\tauc: 0.988812942565\n",
      "\tap@k: 0.980256342842\n",
      "Train:\n",
      "\tloss: 0.0561415232174\n",
      "\tacc: 0.976435643564\n",
      "\tauc: 0.994407030539\n",
      "\tap@k: 1.0\n",
      "Val:\n",
      "\tloss: 0.0900911345316\n",
      "\tacc: 0.962574257426\n",
      "\tauc: 0.989014635756\n",
      "\tap@k: 0.979416125581\n",
      "Train:\n",
      "\tloss: 0.0570111831458\n",
      "\tacc: 0.977425742574\n",
      "\tauc: 0.993739800082\n",
      "\tap@k: 1.0\n",
      "Val:\n",
      "\tloss: 0.0871687744109\n",
      "\tacc: 0.961881188119\n",
      "\tauc: 0.99012014594\n",
      "\tap@k: 1.0\n",
      "Train:\n",
      "\tloss: 0.0494585767878\n",
      "\tacc: 0.979603960396\n",
      "\tauc: 0.994379012344\n",
      "\tap@k: 1.0\n",
      "Val:\n",
      "\tloss: 0.0915999622417\n",
      "\tacc: 0.962475247525\n",
      "\tauc: 0.989300439513\n",
      "\tap@k: 0.988419544154\n",
      "Train:\n",
      "\tloss: 0.0559902391646\n",
      "\tacc: 0.977623762376\n",
      "\tauc: 0.992154570363\n",
      "\tap@k: 1.0\n",
      "Val:\n",
      "\tloss: 0.102728696617\n",
      "\tacc: 0.962277227723\n",
      "\tauc: 0.987249380866\n",
      "\tap@k: 0.995096896327\n",
      "Train:\n",
      "\tloss: 0.504945709263\n",
      "\tacc: 0.944356435644\n",
      "\tauc: 0.970789597319\n",
      "\tap@k: 1.0\n",
      "Val:\n",
      "\tloss: 0.122289112357\n",
      "\tacc: 0.957326732673\n",
      "\tauc: 0.989276904246\n",
      "\tap@k: 0.990356876253\n",
      "Train:\n",
      "\tloss: 0.0807028362821\n",
      "\tacc: 0.972079207921\n",
      "\tauc: 0.993816892309\n",
      "\tap@k: 1.0\n",
      "Val:\n",
      "\tloss: 0.120166694948\n",
      "\tacc: 0.957722772277\n",
      "\tauc: 0.990096474829\n",
      "\tap@k: 1.0\n",
      "Train:\n",
      "\tloss: 0.06667873591\n",
      "\tacc: 0.975940594059\n",
      "\tauc: 0.99438615377\n",
      "\tap@k: 1.0\n",
      "Val:\n",
      "\tloss: 0.116560814476\n",
      "\tacc: 0.956138613861\n",
      "\tauc: 0.989275765525\n",
      "\tap@k: 0.994479103274\n",
      "Train:\n",
      "\tloss: 0.0684172641826\n",
      "\tacc: 0.974059405941\n",
      "\tauc: 0.99309322478\n",
      "\tap@k: 1.0\n",
      "Val:\n",
      "\tloss: 0.0997474275474\n",
      "\tacc: 0.960891089109\n",
      "\tauc: 0.989637442378\n",
      "\tap@k: 0.99304806405\n",
      "Train:\n",
      "\tloss: 0.0614814903728\n",
      "\tacc: 0.976336633663\n",
      "\tauc: 0.993963493775\n",
      "\tap@k: 1.0\n",
      "Val:\n",
      "\tloss: 0.093159336703\n",
      "\tacc: 0.96495049505\n",
      "\tauc: 0.990559866598\n",
      "\tap@k: 0.999873253625\n",
      "Train:\n",
      "\tloss: 0.0543116133225\n",
      "\tacc: 0.978613861386\n",
      "\tauc: 0.995233129999\n",
      "\tap@k: 0.993485556279\n",
      "Val:\n",
      "\tloss: 0.102753945705\n",
      "\tacc: 0.961782178218\n",
      "\tauc: 0.990971395542\n",
      "\tap@k: 1.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-b5162612d573>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mj\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mminibatches_per_epoch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpred_probas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb_desc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb_title\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb_cat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mb_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/timur/.local/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/timur/.local/lib/python2.7/site-packages/theano/gof/op.pyc\u001b[0m in \u001b[0;36mrval\u001b[0;34m(p, i, o, n)\u001b[0m\n\u001b[1;32m    858\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mparams\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNoParams\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m             \u001b[0;31m# default arguments are stored in the closure of `rval`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 860\u001b[0;31m             \u001b[0;32mdef\u001b[0m \u001b[0mrval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode_input_storage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode_output_storage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    861\u001b[0m                 \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "\n",
    "\n",
    "n_epochs = 100\n",
    "batch_size = 100\n",
    "minibatches_per_epoch = 100\n",
    "\n",
    "\n",
    "for i in range(n_epochs):\n",
    "    \n",
    "    #training\n",
    "    epoch_y_true = []\n",
    "    epoch_y_pred = []\n",
    "    \n",
    "    b_c = b_loss = 0\n",
    "    for j, (b_desc,b_title,b_cat, b_y) in enumerate(\n",
    "        iterate_minibatches(desc_tr,title_tr,nontext_tr,target_tr,batchsize=batch_size,shuffle=True)):\n",
    "        if j > minibatches_per_epoch:break\n",
    "            \n",
    "        loss,pred_probas = train_fun(b_desc,b_title,b_cat,b_y)\n",
    "        \n",
    "        b_loss += loss\n",
    "        b_c +=1\n",
    "        \n",
    "        epoch_y_true.append(b_y)\n",
    "        epoch_y_pred.append(pred_probas)\n",
    "\n",
    "    \n",
    "    epoch_y_true = np.concatenate(epoch_y_true)\n",
    "    epoch_y_pred = np.concatenate(epoch_y_pred)\n",
    "    \n",
    "    print 'Train:',i+1,'/',n_epochs\n",
    "    print '\\tloss:',b_loss/b_c\n",
    "    print '\\tacc:',accuracy_score(epoch_y_true,epoch_y_pred>0.)\n",
    "    print '\\tauc:',roc_auc_score(epoch_y_true,epoch_y_pred)\n",
    "    print '\\tap@k:',APatK(epoch_y_true,epoch_y_pred,K = int(len(epoch_y_pred)*0.025)+1)\n",
    "    \n",
    "    \n",
    "    #evaluation\n",
    "    epoch_y_true = []\n",
    "    epoch_y_pred = []\n",
    "    b_c = b_loss = 0\n",
    "    for j, (b_desc,b_title,b_cat, b_y) in enumerate(\n",
    "        iterate_minibatches(desc_ts,title_ts,nontext_ts,target_ts,batchsize=batch_size,shuffle=True)):\n",
    "        if j > minibatches_per_epoch: break\n",
    "        loss,pred_probas = eval_fun(b_desc,b_title,b_cat,b_y)\n",
    "        \n",
    "        b_loss += loss\n",
    "        b_c +=1\n",
    "        \n",
    "        epoch_y_true.append(b_y)\n",
    "        epoch_y_pred.append(pred_probas)\n",
    "\n",
    "    \n",
    "    epoch_y_true = np.concatenate(epoch_y_true)\n",
    "    epoch_y_pred = np.concatenate(epoch_y_pred)\n",
    "    \n",
    "    print \"Val:\"\n",
    "    print '\\tloss:',b_loss/b_c\n",
    "    print '\\tacc:',accuracy_score(epoch_y_true,epoch_y_pred>0.)\n",
    "    print '\\tauc:',roc_auc_score(epoch_y_true,epoch_y_pred)\n",
    "    print '\\tap@k:',APatK(epoch_y_true,epoch_y_pred,K = int(len(epoch_y_pred)*0.025)+1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final evaluation\n",
    "Оценим качество модели по всей тестовой выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores:\n",
      "\tloss: 0.0979782097187\n",
      "\tacc: 0.96265051395\n",
      "\tauc: 0.990674624843\n",
      "\tap@k: 0.998028285713\n",
      "\n",
      "AUC:\n",
      "\tПиши статью. (great)\n",
      "\n",
      "Accuracy:\n",
      "\tОтличный результат! (good)\n",
      "\n",
      "Average precision at K:\n",
      "\tЗасабмить на kaggle! (great) \n",
      "\t Нет, ну честно - выкачай avito_test.tsv, засабмить и скажи, что вышло.\n"
     ]
    }
   ],
   "source": [
    "#evaluation\n",
    "epoch_y_true = []\n",
    "epoch_y_pred = []\n",
    "\n",
    "b_c = b_loss = 0\n",
    "for j, (b_desc,b_title,b_cat, b_y) in enumerate(\n",
    "    iterate_minibatches(desc_ts,title_ts,nontext_ts,target_ts,batchsize=batch_size,shuffle=True)):\n",
    "    loss,pred_probas = eval_fun(b_desc,b_title,b_cat,b_y)\n",
    "\n",
    "    b_loss += loss\n",
    "    b_c +=1\n",
    "\n",
    "    epoch_y_true.append(b_y)\n",
    "    epoch_y_pred.append(pred_probas)\n",
    "\n",
    "\n",
    "epoch_y_true = np.concatenate(epoch_y_true)\n",
    "epoch_y_pred = np.concatenate(epoch_y_pred)\n",
    "\n",
    "final_accuracy = accuracy_score(epoch_y_true,epoch_y_pred>0)\n",
    "final_auc = roc_auc_score(epoch_y_true,epoch_y_pred)\n",
    "final_apatk = APatK(epoch_y_true,epoch_y_pred,K = int(len(epoch_y_pred)*0.025)+1)\n",
    "\n",
    "print \"Scores:\"\n",
    "print '\\tloss:',b_loss/b_c\n",
    "print '\\tacc:',final_accuracy\n",
    "print '\\tauc:',final_auc\n",
    "print '\\tap@k:',final_apatk\n",
    "score(final_accuracy,final_auc,final_apatk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
